{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8288274-f91a-47e4-a0f0-b07cf097cfbf",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Script 3 - Calculate index used in analyses\n",
    "\n",
    "The index we are using to analyze the data was the Area Under the Curve (a.k.a SST Footprint). The mean area below the long term mean is calculated for each month for each EBUS/subregion.\n",
    "\n",
    "| EBUS | Subregion | SST Threshold (Original) | SST Threshold (Modified) | \n",
    "| --- | --- | :---: | :---: | \n",
    "| California | Poleward | 11.88 | 11.88 | \n",
    "| California | Central | 13.07 | 13.07 | \n",
    "| California | Equatorward | 17.78 | 17.78 | \n",
    "| Humboldt | Poleward | 14.12 | 14.12 | \n",
    "| Humboldt | Central | 19.07 | 18.50 | \n",
    "| Humboldt | Equatorward | 18.27 | 18.30 | \n",
    "| Iberian/Canary | Poleward | 16.21 | 16.21 | \n",
    "| Iberian/Canary | Central | 19.26 | 19.08 | \n",
    "| Iberian/Canary | Equatorward | 22.57 | 22.12 | \n",
    "| Benguela | Poleward | 15.34 | 15.63 | \n",
    "| Benguela | Central | NA | 15.07 | \n",
    "| Benguela | Equatorward | 18.18 | 18.18 | \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ef2415",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt \n",
    "import matplotlib.patches as patches\n",
    "import cartopy.feature as cfeature\n",
    "import cartopy.crs as ccrs\n",
    "import math\n",
    "import warnings \n",
    "warnings.simplefilter('ignore') \n",
    "import seaborn as sns\n",
    "import glob\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter\n",
    "from calendar import month_abbr\n",
    "from geopy import distance\n",
    "from matplotlib.ticker import StrMethodFormatter\n",
    "from datetime import datetime\n",
    "import matplotlib.dates as mdates\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b75f7a19-a080-47ca-8121-25aa2d83acf5",
   "metadata": {},
   "source": [
    "### Loop through each EBUS, year, and month and count cells below mean region sst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eddf0f7-b69a-47dc-b5a8-a7e9267d6987",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Open data and calculate seasonal means\n",
    "ddir = '../data/data_download/'\n",
    "ebus = 'Iberian-Canary'\n",
    "fns = glob.glob(ddir+ebus+'/*_MURR_*.nc')\n",
    "ds = xr.open_mfdataset(fns)\n",
    "\n",
    "#calculate seasonal index starting in december\n",
    "ds_season = ds.resample(time = '1QS-DEC').mean()\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26db07f8-6c66-4ed4-a992-6ebdd9f97b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Calculate Seasonal Time Series and Detrend Seasonal Means\n",
    "ddir = '../data/data_download/'\n",
    "ebus_list = ['Iberian-Canary', 'Benguela', 'California', 'Humboldt']\n",
    "\n",
    "ds_season_df = pd.DataFrame()\n",
    "\n",
    "for ebus in ebus_list:\n",
    "    \n",
    "    fns = glob.glob(ddir+ebus+'/*_MURR_*.nc')\n",
    "    ds = xr.open_mfdataset(fns)\n",
    "    \n",
    "    #select out coordinates based on EBUS\n",
    "    if ebus == 'California':\n",
    "        lats = np.array([[28.5,34.5],[34.5,40.4],[40.4,46]]) \n",
    "        lons = np.array([[-124, -113],[-128, -120], [-129, -123]])\n",
    "        sst_upw = [17.780235290527344, 13.065020561218262, 11.875925064086914] #nearshore means (modified subregions)\n",
    "        #sst_upw = [17.780235290527344, 13.065020561218262, 11.875925064086914] #nearshore means (original subregions)\n",
    "        #sst_upw = [17.337725, 14.049598, 13.024406] #long term, full region means\n",
    "        reg = 3\n",
    "    elif ebus == 'Humboldt':\n",
    "        lats = np.array([[-42,-28],[-28,-17],[-17,-10]]) \n",
    "        lons = np.array([[-79,-69],[-76,-69],[-81,-72]]) \n",
    "        sst_upw = [14.118310928344727, 18.504968643188477, 18.300222396850586] #nearshore means (modified supregions)\n",
    "        #sst_upw = [14.118310928344727, 19.07120704650879, 18.2731876373291] #nearshore means (original subregions)\n",
    "        #sst_upw = [14.972103, 19.707349, 19.989355] #long term, full region means\n",
    "        reg = 3\n",
    "    elif ebus == 'Iberian-Canary':\n",
    "        lats = np.array([[15,21.33],[21.33,33],[37, 43.39]]) \n",
    "        lons = np.array([[-21,-16],[-21,-8.75],[-14,-7]]) \n",
    "        sst_upw = [22.11833381652832, 18.946455001831055, 16.212278366088867] #nearshore means (modified subregions with central Iberian changed)\n",
    "        # sst_upw = [22.11833381652832, 19.076478958129883, 16.212278366088867] #nearshore means (modified subregions)\n",
    "        #sst_upw = [22.574838638305664, 19.255435943603516, 16.212278366088867] #nearshore means (original subregions)\n",
    "        #sst_upw = [23.338499, 20.541109, 17.248304] #long term, full region means\n",
    "        reg = 3\n",
    "    else: #Benguela\n",
    "        lats = np.array([[-34.8,-28.63],[-28.63, -22],[-22,-15]]) \n",
    "        lons = np.array([[13, 20],[10, 17],[8, 15]])\n",
    "        sst_upw = [15.6278657913208, 15.074623107910156, 18.181407928466797] #nearshore means (modified subregions)\n",
    "        #sst_upw = [15.341087341308594, 18.181407928466797] #nearshore means (original subregions)\n",
    "        #sst_upw = [17.249544, 19.3302917] #long term, full region means\n",
    "        reg = 3\n",
    "        \n",
    "    #loop through the subregions of the ebus region\n",
    "    for region in range(reg):\n",
    "\n",
    "        #slice the data to the sub region\n",
    "        ds_slice = ds.sel(lat=slice(lats[region,0],lats[region,1]),lon=slice(lons[region,0],lons[region,1]))\n",
    "\n",
    "        #calculate seasonal index starting in december\n",
    "        ds_season = ds_slice.resample(time = '1QS-DEC').mean()\n",
    "        ds_temp = ds_season.groupby('time').mean(...).to_dataframe()\n",
    "        ds_temp = ds_temp.reset_index()\n",
    "        ds_temp['EBUS'] = ebus\n",
    "        ds_temp['Subregion'] = region\n",
    "\n",
    "        ds_season_df = pd.concat([ds_season_df, ds_temp])\n",
    "        \n",
    "#relabel regions\n",
    "for ebus in ebus_list:\n",
    "    if ebus in ['California', 'Iberian-Canary']:\n",
    "        \n",
    "        ds_season_df.loc[(ds_season_df['EBUS'] == ebus) & (ds_season_df['Subregion'] == 0), 'Subregion'] = 'Equatorward'\n",
    "        ds_season_df.loc[(ds_season_df['EBUS'] == ebus) & (ds_season_df['Subregion'] == 1), 'Subregion'] = 'Central'\n",
    "        ds_season_df.loc[(ds_season_df['EBUS'] == ebus) & (ds_season_df['Subregion'] == 2), 'Subregion'] = 'Poleward'\n",
    "\n",
    "    elif ebus == 'Bengula':\n",
    "        \n",
    "        ds_season_df.loc[(ds_season_df['EBUS'] == ebus) & (ds_season_df['Subregion'] == 0), 'Subregion'] = 'Poleward'\n",
    "        ds_season_df.loc[(ds_season_df['EBUS'] == ebus) & (ds_season_df['Subregion'] == 1), 'Subregion'] = 'Equatorward'\n",
    "        \n",
    "    else:\n",
    "\n",
    "        ds_season_df.loc[(ds_season_df['EBUS'] == ebus) & (ds_season_df['Subregion'] == 0), 'Subregion'] = 'Poleward'\n",
    "        ds_season_df.loc[(ds_season_df['EBUS'] == ebus) & (ds_season_df['Subregion'] == 1), 'Subregion'] = 'Central'\n",
    "        ds_season_df.loc[(ds_season_df['EBUS'] == ebus) & (ds_season_df['Subregion'] == 2), 'Subregion'] = 'Equatorward'\n",
    "\n",
    "#correct Benguela name\n",
    "ds_season_df.loc[ds_season_df['EBUS'] == 'Bengula', 'EBUS'] = 'Benguela'\n",
    "\n",
    "#extract out the month as a string\n",
    "ds_season_df['time_str'] = ds_season_df['time'].dt.strftime('%m')\n",
    "\n",
    "#calculate the seasonal means for each EBUS and Subregion\n",
    "season_means = ds_season_df.groupby(['EBUS', 'Subregion', 'time_str']).mean().reset_index()\n",
    "season_means = season_means.rename({'analysed_sst':'analysed_sst_mean'}, axis = 1)\n",
    "\n",
    "#join the seasonal means with the dataframe\n",
    "season_combined = ds_season_df.merge(season_means, on=['EBUS', 'Subregion', 'time_str'], how='left') \n",
    "\n",
    "#calculate the detrended values for each season\n",
    "season_combined = season_combined.assign(analysed_sst_detrended = lambda x: x['analysed_sst'] - x['analysed_sst_mean'])\n",
    "\n",
    "#save the data\n",
    "season_combined.to_csv('../data/EBUS_Seasonal_Detrended_Means.csv', index = False)\n",
    "season_combined"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c729f2-1a3a-4f66-a2b2-1060036b5546",
   "metadata": {},
   "source": [
    "## **The cell below takes a long time to run**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d7d5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Calculate the first index, the area under the cruve\n",
    "#create empty dataframe\n",
    "upwelling = pd.DataFrame(index=[0])\n",
    "\n",
    "#directory path\n",
    "ddir = '../data/data_download/'\n",
    "#list of ebus regions\n",
    "ebus_list = ['Iberian-Canary', 'Bengula', 'California', 'Humboldt']\n",
    "\n",
    "#loop through different ebus regions\n",
    "for ebus in ebus_list: \n",
    "\n",
    "    #select out coordinates based on EBUS\n",
    "    if ebus == 'California':\n",
    "        lats = np.array([[28.5,34.5],[34.5,40.4],[40.4,46]]) \n",
    "        lons = np.array([[-124, -113],[-128, -120], [-129, -123]])\n",
    "        sst_upw = [17.780235290527344, 13.065020561218262, 11.875925064086914] #nearshore means (modified subregions)\n",
    "        #sst_upw = [17.780235290527344, 13.065020561218262, 11.875925064086914] #nearshore means (original subregions)\n",
    "        #sst_upw = [17.337725, 14.049598, 13.024406] #long term, full region means\n",
    "        reg = 3\n",
    "    elif ebus == 'Humboldt':\n",
    "        lats = np.array([[-42,-28],[-28,-17],[-17,-10]]) \n",
    "        lons = np.array([[-79,-69],[-76,-69],[-81,-72]]) \n",
    "        sst_upw = [14.118310928344727, 18.504968643188477, 18.300222396850586] #nearshore means (modified supregions)\n",
    "        #sst_upw = [14.118310928344727, 19.07120704650879, 18.2731876373291] #nearshore means (original subregions)\n",
    "        #sst_upw = [14.972103, 19.707349, 19.989355] #long term, full region means\n",
    "        reg = 3\n",
    "    elif ebus == 'Iberian-Canary':\n",
    "        lats = np.array([[15,21.33],[21.33,33],[37, 43.39]]) \n",
    "        lons = np.array([[-21,-16],[-21,-8.75],[-14,-7]]) \n",
    "        sst_upw = [22.11833381652832, 18.946455001831055, 16.212278366088867] #nearshore means (modified subregions with central Iberian changed)\n",
    "        # sst_upw = [22.11833381652832, 19.076478958129883, 16.212278366088867] #nearshore means (modified subregions)\n",
    "        #sst_upw = [22.574838638305664, 19.255435943603516, 16.212278366088867] #nearshore means (original subregions)\n",
    "        #sst_upw = [23.338499, 20.541109, 17.248304] #long term, full region means\n",
    "        reg = 3\n",
    "    else: #Benguela\n",
    "        lats = np.array([[-34.8,-28.63],[-28.63, -22],[-22,-15]]) \n",
    "        lons = np.array([[13, 20],[10, 17],[8, 15]])\n",
    "        sst_upw = [15.6278657913208, 15.074623107910156, 18.181407928466797] #nearshore means (modified subregions)\n",
    "        #sst_upw = [15.341087341308594, 18.181407928466797] #nearshore means (original subregions)\n",
    "        #sst_upw = [17.249544, 19.3302917] #long term, full region means\n",
    "        reg = 3\n",
    "\n",
    "    #open the specific ebus region\n",
    "    fns = glob.glob(ddir+ebus+'/*_MURR_*.nc')\n",
    "    ds = xr.open_mfdataset(fns)\n",
    "    \n",
    "    #resample data to be seasonal\n",
    "    #ds = ds.resample(time = '1QS-DEC').mean()\n",
    "\n",
    "    #loop through the subregions of the ebus region\n",
    "    for region in range(reg):\n",
    "    \n",
    "        #loop through each year\n",
    "        for i in ds.analysed_sst.time.values:\n",
    "            #create an empty dictionary\n",
    "            region_dict = {}\n",
    "            \n",
    "            #slice the data to the sub region\n",
    "            ds_slice = ds.sel(lat=slice(lats[region,0],lats[region,1]),lon=slice(lons[region,0],lons[region,1]))\n",
    "            #select out a single year and month\n",
    "            tmp0 = ds_slice.analysed_sst.where(ds.time == i, drop=True)\n",
    "            #filter the data so it's less than the mean annual sst for the region\n",
    "            upwarea = tmp0.where(tmp0.values <= sst_upw[region])\n",
    "            #convert it to a dataframe \n",
    "            upwarea_df = upwarea.to_dataframe()\n",
    "            #count the number of cells to be the count of cells below the mean sst\n",
    "            points = len(upwarea_df[upwarea_df['analysed_sst'].notnull()])\n",
    "            #calculate total area (without nans)\n",
    "            totals = xr.where(~np.isnan(tmp0.values), 1, 0).sum() \n",
    "            #convert it to a percent\n",
    "            percent = np.around(points / totals * 100,2)\n",
    "\n",
    "            #store each model parameter in the dictionary\n",
    "            region_dict['EBUS'] = ebus\n",
    "            region_dict['Region'] = str(region)\n",
    "            region_dict['Year'] = str(int(tmp0.time.dt.year.values))\n",
    "            region_dict['Month'] = str(int(tmp0.time.dt.month.values))\n",
    "            region_dict['Points'] = str(points)\n",
    "            region_dict['Percent'] = percent\n",
    "            \n",
    "\n",
    "            #add the dictionary as a row in the dataframe\n",
    "            upwelling = upwelling.append(region_dict, ignore_index = True)\n",
    "    print('Finished: ' + ebus)\n",
    "\n",
    "#drop the first row (filler) and save file\n",
    "upwelling = upwelling.drop(labels = 0, axis = 0)\n",
    "upwelling.to_csv(ddir+ebus+'_upwelling_areas_seasonal_nearshore_Modified-Subregions.csv', index = False)\n",
    "upwelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46d7c76-030c-4302-8393-60393cd2635d",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Rejoin the files into one (originally split up cause accessing the google drive data for all four timed out)\n",
    "ebus_list = ['Iberian-Canary', 'Benguela', 'California', 'Humboldt']\n",
    "\n",
    "upwelling_joined = pd.DataFrame()\n",
    "\n",
    "for ebus in ebus_list:\n",
    "    temp = pd.read_csv(ddir+ebus+'_upwelling_areas_seasonal_nearshore_Modified-Subregions.csv')\n",
    "    upwelling_joined = pd.concat([upwelling_joined, temp])\n",
    "    \n",
    "upwelling_joined.to_csv(ddir + 'upwelling_areas_seasonal_nearshore_Modified-Subregions.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141a59ce-18bd-4552-9063-53329c692869",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Clean up data\n",
    "#read in upwelling results\n",
    "ddir = '../data/data_download/'\n",
    "upwelling = pd.read_csv(ddir+'upwelling_areas_seasonal_nearshore_Modified-Subregions.csv')\n",
    "upwelling['Region_name'] = 'NA'\n",
    "upwelling['EBUS_name'] = 'NA'\n",
    "upwelling['Hemisphere'] = 'NA'\n",
    "\n",
    "#clean up the columns of the data\n",
    "for i in range(len(upwelling)):\n",
    "    if upwelling['EBUS'][i] == 'Bengula':\n",
    "        upwelling['EBUS_name'][i] = 'Benguela'\n",
    "        if upwelling['Region'][i] == 0:\n",
    "            upwelling['Region_name'][i] = 'South'\n",
    "        else:\n",
    "            upwelling['Region_name'][i] = 'North'\n",
    "    else:\n",
    "        upwelling['EBUS_name'][i] = upwelling['EBUS'][i]\n",
    "        if upwelling['Region'][i] == 0:\n",
    "            upwelling['Region_name'][i] = 'South'\n",
    "        elif upwelling['Region'][i] == 1:\n",
    "            upwelling['Region_name'][i] = 'Central'\n",
    "        else:\n",
    "            upwelling['Region_name'][i] = 'North'\n",
    "            \n",
    "for i in range(len(upwelling)):\n",
    "    if (upwelling['EBUS_name'][i] == 'Benguela') | (upwelling['EBUS_name'][i] == 'Humboldt'):\n",
    "        upwelling['Hemisphere'][i] = 'South'\n",
    "    else:\n",
    "        upwelling['Hemisphere'][i] = 'North'\n",
    "        \n",
    "for i in range(len(upwelling)):\n",
    "    if upwelling['Hemisphere'][i] == 'North':\n",
    "        if upwelling['Region_name'][i] == 'North':\n",
    "            upwelling['Region_name'][i] = 'Poleward'\n",
    "        elif upwelling['Region_name'][i] == 'Central':\n",
    "            upwelling['Region_name'][i] = 'Central'\n",
    "        else:\n",
    "            upwelling['Region_name'][i] = 'Equatorward'\n",
    "    else:\n",
    "        if upwelling['Region_name'][i] == 'South':\n",
    "            upwelling['Region_name'][i] = 'Poleward'\n",
    "        elif upwelling['Region_name'][i] == 'Central':\n",
    "            upwelling['Region_name'][i] = 'Central'\n",
    "        else:\n",
    "            upwelling['Region_name'][i] = 'Equatorward'\n",
    "            \n",
    "upwelling['Random_name'] = upwelling['EBUS_name'] + '-' + upwelling['Region_name']\n",
    "upwelling_north = upwelling[upwelling['Hemisphere'] == 'North']\n",
    "upwelling.to_csv('../data/upwellingfootprint_monthly_nearshore_updated_Modified-Subregions.csv', index = False)\n",
    "upwelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b04636ef-bef9-493d-b610-f0dc652f1586",
   "metadata": {
    "tags": []
   },
   "source": [
    "## ERA5 Charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1680969b-eb72-452a-8bdb-cbb8aed625cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in benguela data\n",
    "beng_era5 = xr.open_dataset('../data/data_download/Benguela_ERA5.nc') #save data\n",
    "beng_era5.close()\n",
    "beng_df = beng_era5.to_dataframe().reset_index()\n",
    "beng_df = beng_df[~beng_df['northward_wind_at_10_metres'].isnull()]\n",
    "beng_df['EBUS'] = 'Benguela'\n",
    "\n",
    "#read in california data\n",
    "cali_era5 = xr.open_dataset('../data/data_download/California_ERA5.nc') #save data\n",
    "cali_era5.close()\n",
    "cali_df = cali_era5.to_dataframe().reset_index()\n",
    "cali_df = cali_df[~cali_df['northward_wind_at_10_metres'].isnull()]\n",
    "cali_df['EBUS'] = 'California'\n",
    "\n",
    "#read in humboldt data\n",
    "hum_era5 = xr.open_dataset('../data/data_download/Humboldt_ERA5.nc') #save data\n",
    "hum_era5.close()\n",
    "hum_df = hum_era5.to_dataframe().reset_index()\n",
    "hum_df = hum_df[~hum_df['northward_wind_at_10_metres'].isnull()]\n",
    "hum_df['EBUS'] = 'Humboldt'\n",
    "\n",
    "#read in iberian data\n",
    "iber_era5 = xr.open_dataset('../data/data_download/Iberian-Canary_ERA5.nc') #save data\n",
    "iber_era5.close()\n",
    "iber_df = iber_era5.to_dataframe().reset_index()\n",
    "iber_df = iber_df[~iber_df['northward_wind_at_10_metres'].isnull()]\n",
    "iber_df['EBUS'] = 'Iberian-Canary'\n",
    "\n",
    "#join all the regions\n",
    "frames = [beng_df, cali_df, hum_df, iber_df]\n",
    "era5_joined = pd.concat(frames)\n",
    "era5_joined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdac0e55-2aa7-42bd-9229-3b78a748c624",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add in the subregions \n",
    "ebus_list = ['California', 'Humboldt', 'Iberian-Canary', 'Benguela']\n",
    "era5_joined['Region'] = 'NA'\n",
    "\n",
    "#loop through each ebus and add in the regions\n",
    "for ebus in ebus_list:\n",
    "    #select out coordinates based on EBUS\n",
    "    if ebus == 'California':\n",
    "        \n",
    "        #list California region boundaries\n",
    "        lats = np.array([[28.5,34.5],[34.5,40.4],[40.4,46]]) \n",
    "                \n",
    "        #add in regions\n",
    "        era5_joined['Region'][(era5_joined['lat'] >= lats[0][0]) & (era5_joined['lat'] <= lats[0][1]) & (era5_joined['EBUS'] == ebus)] = 'South'\n",
    "        era5_joined['Region'][(era5_joined['lat'] >= lats[1][0]) & (era5_joined['lat'] <= lats[1][1]) & (era5_joined['EBUS'] == ebus)] = 'Central'\n",
    "        era5_joined['Region'][(era5_joined['lat'] >= lats[2][0]) & (era5_joined['lat'] <= lats[2][1]) & (era5_joined['EBUS'] == ebus)] = 'North'\n",
    "    \n",
    "    elif ebus == 'Humboldt':\n",
    "        \n",
    "        #list Humboldt region boundaries\n",
    "        lats = np.array([[-42,-28],[-25,-17],[-15,-10]]) \n",
    "        \n",
    "        #add in regions\n",
    "        era5_joined['Region'][(era5_joined['lat'] >= lats[0][0]) & (era5_joined['lat'] <= lats[0][1]) & (era5_joined['EBUS'] == ebus)] = 'South'\n",
    "        era5_joined['Region'][(era5_joined['lat'] >= lats[1][0]) & (era5_joined['lat'] <= lats[1][1]) & (era5_joined['EBUS'] == ebus)] = 'Central'\n",
    "        era5_joined['Region'][(era5_joined['lat'] >= lats[2][0]) & (era5_joined['lat'] <= lats[2][1]) & (era5_joined['EBUS'] == ebus)] = 'North'\n",
    "        \n",
    "    elif ebus == 'Iberian-Canary':\n",
    "        \n",
    "        #list Iberian-Canary region boundaries\n",
    "        lats = np.array([[15,20],[20,30],[37, 43.39]]) \n",
    "        \n",
    "        #add in regions\n",
    "        era5_joined['Region'][(era5_joined['lat'] >= lats[0][0]) & (era5_joined['lat'] <= lats[0][1]) & (era5_joined['EBUS'] == ebus)] = 'South'\n",
    "        era5_joined['Region'][(era5_joined['lat'] >= lats[1][0]) & (era5_joined['lat'] <= lats[1][1]) & (era5_joined['EBUS'] == ebus)] = 'Central'\n",
    "        era5_joined['Region'][(era5_joined['lat'] >= lats[2][0]) & (era5_joined['lat'] <= lats[2][1]) & (era5_joined['EBUS'] == ebus)] = 'North'\n",
    "\n",
    "        \n",
    "    else: #Benguela\n",
    "        \n",
    "        #list out Benguela region boundaries\n",
    "        lats = np.array([[-34.8,-22],[-22,-15]]) \n",
    "     \n",
    "        #add in regions\n",
    "        era5_joined['Region'][(era5_joined['lat'] >= lats[0][0]) & (era5_joined['lat'] <= lats[0][1]) & (era5_joined['EBUS'] == ebus)] = 'South'\n",
    "        era5_joined['Region'][(era5_joined['lat'] >= lats[1][0]) & (era5_joined['lat'] <= lats[1][1]) & (era5_joined['EBUS'] == ebus)] = 'North'\n",
    "        \n",
    "era5_joined = era5_joined.groupby(['time0', 'EBUS', 'Region']).mean().reset_index()\n",
    "era5_joined = era5_joined[era5_joined.Region != 'NA']\n",
    "era5_joined['sea_surface_temperature'] = era5_joined['sea_surface_temperature'] - 273.15\n",
    "era5_joined = era5_joined.rename({'northward_wind_at_10_metres': 'ERA5_northward_wind_at_10_metres', \n",
    "                                  'northward_wind_stress': 'ERA5_northward_wind_stress',\n",
    "                                 'sea_surface_temperature': 'ERA5_sea_surface_temperature'}, axis = 1)\n",
    "era5_joined.to_csv('../data/ERA5_monthly_means.csv', index = False)\n",
    "era5_joined"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeef8971-2503-4600-b1fb-070f5796a3c0",
   "metadata": {},
   "source": [
    "## ERA5 and MURR Climatology\n",
    "\n",
    "### Calculate monthly means temps for MURR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f886bdad-8416-4e13-9b8c-faa55ebe9233",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddir = '../data/data_download/'\n",
    "\n",
    "#create empty dataframe\n",
    "temps = pd.DataFrame(index=[0])\n",
    "\n",
    "#list of ebus regions\n",
    "ebus_list = ['California', 'Humboldt', 'Iberian-Canary', 'Bengula']\n",
    "\n",
    "#loop through different ebus regions\n",
    "for ebus in ebus_list: \n",
    "\n",
    "    #select out coordinates based on EBUS\n",
    "    if ebus == 'California':\n",
    "        lats = np.array([[28.5,34.5],[34.5,40.4],[40.4,46]]) \n",
    "        lons = np.array([[-124, -113],[-128, -120], [-129, -123]])\n",
    "        sst_upw = [17.337725, 14.049598, 13.024406]\n",
    "        reg = ['South', 'Central', 'North']\n",
    "        ebus_name = ebus\n",
    "    elif ebus == 'Humboldt':\n",
    "        lats = np.array([[-42,-28],[-25,-17],[-15,-10]]) \n",
    "        lons = np.array([[-79,-69],[-76,-69],[-81,-75]]) \n",
    "        sst_upw = [14.972103, 19.707349, 19.989355]\n",
    "        reg = ['South', 'Central', 'North']\n",
    "        ebus_name = ebus\n",
    "    elif ebus == 'Iberian-Canary':\n",
    "        lats = np.array([[15,20],[20,30],[37, 43.39]]) \n",
    "        lons = np.array([[-21,-16],[-21,-9],[-14,-7]]) \n",
    "        sst_upw = [23.338499, 20.541109, 17.248304]\n",
    "        reg = ['South', 'Central', 'North']\n",
    "        ebus_name = ebus\n",
    "    else: #Bengula\n",
    "        lats = np.array([[-34.8,-22],[-22,-15]]) \n",
    "        lons = np.array([[10, 19],[8, 15]])\n",
    "        sst_upw = [17.249544, 19.3302917]\n",
    "        ebus_name = 'Benguela'\n",
    "        reg = ['South', 'North']\n",
    "\n",
    "    #open the specific ebus region\n",
    "    fns = glob.glob(ddir+ebus+'/*.nc')\n",
    "    ds = xr.open_mfdataset(fns)\n",
    "\n",
    "    #loop through the subregions of the ebus region\n",
    "    for index, region in enumerate(reg):\n",
    "        \n",
    "        #slice the data to the sub region\n",
    "        ds_slice = ds.sel(lat=slice(lats[index,0],lats[index,1]),lon=slice(lons[index,0],lons[index,1]))\n",
    "        ds_mean = ds_slice.analysed_sst.resample(time = 'M').mean(..., skipna = True).to_dataframe().rename(columns={\"analysed_sst\": \"Mean\"}).reset_index()\n",
    "        ds_10 = ds_slice.analysed_sst.resample(time = 'M').quantile(0.1, ..., skipna = True).to_dataframe().rename(columns={\"analysed_sst\": \"10thPerc\"}).reset_index()\n",
    "        ds_90 = ds_slice.analysed_sst.resample(time = 'M').quantile(0.9, ..., skipna = True).to_dataframe().rename(columns={\"analysed_sst\": \"90thPerc\"}).reset_index()\n",
    "\n",
    "        #join values\n",
    "        df = ds_mean.merge(ds_10,on='time').merge(ds_90,on='time')\n",
    "        df = df.drop(['quantile_x', 'quantile_y'], axis = 1)\n",
    "        df['EBUS'] = ebus_name\n",
    "        df['Region'] = reg[index]\n",
    "        \n",
    "        #join with existing dataframe\n",
    "        temps = temps.append(df, ignore_index = True)\n",
    "    \n",
    "temps = temps.drop(labels = 0, axis = 0)\n",
    "temps = temps.rename({'Mean':'MURR_Mean', '10thPerc':'MURR_10thPerc', '90thPerc':'MURR_90thPerc'}, axis = 1)\n",
    "temps.to_csv('../data/MURR_monthly_means.csv', index = False)\n",
    "temps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8694dc5f-9326-4929-bea9-653199c3724d",
   "metadata": {},
   "source": [
    "#### Offshore and Onshore MUR calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a0bf89-e495-46c1-aead-f6ea0a122e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddir = '../data/data_download/Offshore_Onshorebands/'\n",
    "\n",
    "onshore_offshore = pd.DataFrame(index = [0])\n",
    "\n",
    "for shore in ['Nearshore', 'Offshore']:\n",
    "\n",
    "    #create empty dataframe\n",
    "    temps = pd.DataFrame(index=[0])\n",
    "\n",
    "    #list of ebus regions\n",
    "    ebus_list = ['California', 'Humboldt', 'Iberian-Canary', 'Bengula']\n",
    "\n",
    "    #loop through different ebus regions\n",
    "    for ebus in ebus_list: \n",
    "\n",
    "        #select out coordinates based on EBUS\n",
    "        if ebus == 'California':\n",
    "            lats = np.array([[28.5,34.5],[34.5,40.4],[40.4,46]]) \n",
    "            sst_upw = [17.337725, 14.049598, 13.024406]\n",
    "            reg = ['South', 'Central', 'North']\n",
    "            ebus_name = ebus\n",
    "        elif ebus == 'Humboldt':\n",
    "            lats = np.array([[-42,-28],[-25,-17],[-15,-10]]) \n",
    "            sst_upw = [14.972103, 19.707349, 19.989355]\n",
    "            reg = ['South', 'Central', 'North']\n",
    "            ebus_name = ebus\n",
    "        elif ebus == 'Iberian-Canary':\n",
    "            lats = np.array([[15,20],[20,30],[37, 43.39]]) \n",
    "            sst_upw = [23.338499, 20.541109, 17.248304]\n",
    "            reg = ['South', 'Central', 'North']\n",
    "            ebus_name = ebus\n",
    "        else: #Bengula\n",
    "            lats = np.array([[-34.8,-22],[-22,-15]]) \n",
    "            sst_upw = [17.249544, 19.3302917]\n",
    "            ebus_name = 'Benguela'\n",
    "            reg = ['South', 'North']\n",
    "\n",
    "        #open the specific ebus region\n",
    "        fns = glob.glob(ddir+ebus+'*'+shore+'*.nc')\n",
    "        ds = xr.open_mfdataset(fns)\n",
    "        ds.close()\n",
    "\n",
    "        #loop through the subregions of the ebus region\n",
    "        for index, region in enumerate(reg):\n",
    "\n",
    "            #slice the data to the sub region\n",
    "            ds_slice = ds.sel(lat=slice(lats[index,0],lats[index,1]))\n",
    "            ds_mean = ds_slice.analysed_sst.resample(time = 'M').mean(..., skipna = True).to_dataframe().rename(columns={\"analysed_sst\": \"Mean\"}).reset_index()\n",
    "            ds_10 = ds_slice.analysed_sst.resample(time = 'M').quantile(0.1, ..., skipna = True).to_dataframe().rename(columns={\"analysed_sst\": \"10thPerc\"}).reset_index()\n",
    "            ds_90 = ds_slice.analysed_sst.resample(time = 'M').quantile(0.9, ..., skipna = True).to_dataframe().rename(columns={\"analysed_sst\": \"90thPerc\"}).reset_index()\n",
    "\n",
    "            #join values\n",
    "            df = ds_mean.merge(ds_10,on='time').merge(ds_90,on='time')\n",
    "            df = df.drop(['quantile_x', 'quantile_y'], axis = 1)\n",
    "            df['EBUS'] = ebus_name\n",
    "            df['Region'] = reg[index]\n",
    "\n",
    "            #join with existing dataframe\n",
    "            temps = temps.append(df, ignore_index = True)\n",
    "\n",
    "    temps = temps.drop(labels = 0, axis = 0)\n",
    "    temps = temps.rename({'Mean':'MURR_Mean', '10thPerc':'MURR_10thPerc', '90thPerc':'MURR_90thPerc'}, axis = 1)\n",
    "    \n",
    "    temps['Shore'] = shore\n",
    "    #temps.to_csv('./data/MURR_monthly_means.csv', index = False)\n",
    "    \n",
    "    onshore_offshore = pd.concat([onshore_offshore, temps])\n",
    "    \n",
    "onshore_offshore = onshore_offshore.drop(labels = 0, axis = 0)\n",
    "onshore_offshore = onshore_offshore.reset_index().drop('index', axis = 1)\n",
    "onshore_offshore.to_csv('../data/MURR_Nearshore_Offshore_monthly_means.csv', index = False)\n",
    "onshore_offshore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292356fa-5396-460a-9d80-9bef39ef02ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
